{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls5_2010_val = np.load('./data/preds/ls5_2010_preds_val_quant.npy')\n",
    "ls7_2010_val = np.load('./data/preds/ls7_2010_preds_val_quant.npy')\n",
    "ls7_2017_val = np.load('./data/preds/ls7_2017_preds_val_quant.npy')\n",
    "ls8_2017_val = np.load('./data/preds/ls8_2017_preds_val_quant.npy')\n",
    "val_masks = np.load('./data/preds/val_masks.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If True, chooses cutoffs to maximize IoU\n",
    "# If False, chooses cutoffs to minimize difference between precision and recall\n",
    "MAX_IOU_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(tp, fp, fn, tn):\n",
    "    iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "    f1 = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "    prec = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")\n",
    "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro\")\n",
    "    return np.array([iou, f1, prec,recall])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Find balanced precision/recall cutoff for LS8 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = np.arange(0,1.0,0.001)\n",
    "stats_arrays = []\n",
    "preds = ls8_2017_val\n",
    "masks = torch.Tensor(val_masks).long()\n",
    "for cutoff in cutoffs:\n",
    "    preds_binary = torch.Tensor(preds>cutoff).long()\n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(preds_binary,\n",
    "                                           masks,\n",
    "                                            mode=\"binary\")\n",
    "\n",
    "    stats_arrays.append(compute_stats(tp, fp, fn, tn))\n",
    "all_stats = np.vstack(stats_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cutoffs, all_stats[:,3])\n",
    "plt.plot(cutoffs, all_stats[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAX_IOU_MODE:\n",
    "    best_index = np.argmax(all_stats[:,0])\n",
    "else:\n",
    "    best_index = np.argmin(np.abs(all_stats[:,2]-all_stats[:,3]))\n",
    "print(all_stats[best_index])\n",
    "best_cutoff_ls8 = np.median(cutoffs[np.where(all_stats[:,0] == all_stats[best_index, 0])[0]])\n",
    "print(best_cutoff_ls8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Balanced precision/recall cutoff for LS7 using LS8 as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = np.arange(0,0.005,0.0001)\n",
    "stats_arrays = []\n",
    "preds = ls7_2017_val\n",
    "masks = torch.Tensor(ls8_2017_val>best_cutoff_ls8).long()\n",
    "for cutoff in cutoffs:\n",
    "    preds_binary = torch.Tensor(preds>cutoff).long()\n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(preds_binary,\n",
    "                                           masks,\n",
    "                                            mode=\"binary\")\n",
    "\n",
    "    stats_arrays.append(compute_stats(tp, fp, fn, tn))\n",
    "all_stats = np.vstack(stats_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cutoffs, all_stats[:,3])\n",
    "plt.plot(cutoffs, all_stats[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAX_IOU_MODE:\n",
    "    best_index = np.argmax(all_stats[:,0])\n",
    "else:\n",
    "    best_index = np.argmin(np.abs(all_stats[:,2]-all_stats[:,3]))\n",
    "print(all_stats[best_index])\n",
    "best_cutoff_ls7 = np.median(cutoffs[np.where(all_stats[:,0] == all_stats[best_index, 0])[0]])\n",
    "print(best_cutoff_ls7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Balanced precision/recall cutoff for LS5 using LS7 2010 as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = np.arange(0,0.1,0.001)\n",
    "stats_arrays = []\n",
    "preds = ls5_2010_val\n",
    "masks = torch.Tensor(ls7_2010_val>best_cutoff_ls7).long()\n",
    "for cutoff in cutoffs:\n",
    "    preds_binary = torch.Tensor(preds>cutoff).long()\n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(preds_binary,\n",
    "                                           masks,\n",
    "                                            mode=\"binary\")\n",
    "\n",
    "    stats_arrays.append(compute_stats(tp, fp, fn, tn))\n",
    "all_stats = np.vstack(stats_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cutoffs, all_stats[:,3])\n",
    "plt.plot(cutoffs, all_stats[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAX_IOU_MODE:\n",
    "    best_index = np.argmax(all_stats[:,0])\n",
    "else:\n",
    "    best_index = np.argmin(np.abs(all_stats[:,2]-all_stats[:,3]))\n",
    "print(all_stats[best_index])\n",
    "best_cutoff_ls5 = np.median(cutoffs[np.where(all_stats[:,0] == all_stats[best_index, 0])[0]])\n",
    "print(best_cutoff_ls5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate against Val Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(ls8_2017_val> best_cutoff_ls8))\n",
    "print(np.sum(ls7_2017_val> best_cutoff_ls7))\n",
    "print(np.sum(ls7_2010_val> best_cutoff_ls7))\n",
    "print(np.sum(ls5_2010_val> best_cutoff_ls5))\n",
    "print(np.sum(val_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LS8 2017: ',compute_stats(*smp.metrics.get_stats(torch.Tensor(ls8_2017_val>best_cutoff_ls8).long(),\n",
    "                                       torch.Tensor(val_masks).long(),\n",
    "                                        mode=\"binary\")\n",
    "))\n",
    "print('LS7 2017: ',compute_stats(*smp.metrics.get_stats(torch.Tensor(ls7_2017_val>best_cutoff_ls7).long(),\n",
    "                                       torch.Tensor(val_masks).long(),\n",
    "                                        mode=\"binary\")\n",
    "))\n",
    "print('LS7 2010: ',compute_stats(*smp.metrics.get_stats(torch.Tensor(ls7_2010_val>best_cutoff_ls7).long(),\n",
    "                                       torch.Tensor(val_masks).long(),\n",
    "                                        mode=\"binary\")\n",
    "))\n",
    "print('LS5 2010: ',compute_stats(*smp.metrics.get_stats(torch.Tensor(ls5_2010_val>best_cutoff_ls5).long(),\n",
    "                                       torch.Tensor(val_masks).long(),\n",
    "                                        mode=\"binary\")\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls5_2010_test = np.load('./data/preds/ls5_2010_preds_test_quant.npy')\n",
    "ls7_2010_test = np.load('./data/preds/ls7_2010_preds_test_quant.npy')\n",
    "ls7_2017_test = np.load('./data/preds/ls7_2017_preds_test_quant.npy')\n",
    "ls8_2017_test = np.load('./data/preds/ls8_2017_preds_test_quant.npy')\n",
    "test_masks = np.load('./data/preds/test_masks.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Against each other\n",
    "print('LS8 vs LS7 2017: ',compute_stats(*smp.metrics.get_stats(torch.Tensor(ls7_2017_test>best_cutoff_ls7).long(),\n",
    "                                       torch.Tensor(ls8_2017_test>best_cutoff_ls8).long(),\n",
    "                                        mode=\"binary\")\n",
    "                                        ))\n",
    "print('LS7 vs LS5 2010: ',compute_stats(*smp.metrics.get_stats(torch.Tensor(ls5_2010_test>best_cutoff_ls5).long(),\n",
    "                                       torch.Tensor(ls7_2010_test>best_cutoff_ls7).long(),\n",
    "                                        mode=\"binary\")\n",
    "                                        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Against masks\n",
    "print('LS8 2017: ',compute_stats(*smp.metrics.get_stats(torch.Tensor(ls8_2017_test>best_cutoff_ls8).long(),\n",
    "                                       torch.Tensor(test_masks).long(),\n",
    "                                        mode=\"binary\")\n",
    "))\n",
    "print('LS7 2017: ',compute_stats(*smp.metrics.get_stats(torch.Tensor(ls7_2017_test>best_cutoff_ls7).long(),\n",
    "                                       torch.Tensor(test_masks).long(),\n",
    "                                        mode=\"binary\")\n",
    "))\n",
    "print('LS7 2010: ',compute_stats(*smp.metrics.get_stats(torch.Tensor(ls7_2010_test>best_cutoff_ls7).long(),\n",
    "                                       torch.Tensor(test_masks).long(),\n",
    "                                        mode=\"binary\")\n",
    "))\n",
    "print('LS5 2010: ',compute_stats(*smp.metrics.get_stats(torch.Tensor(ls5_2010_test>best_cutoff_ls5).long(),\n",
    "                                       torch.Tensor(test_masks).long(),\n",
    "                                        mode=\"binary\")\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(ls8_2017_test> best_cutoff_ls8))\n",
    "print(np.sum(ls7_2017_test> best_cutoff_ls7))\n",
    "print(np.sum(ls7_2010_test> best_cutoff_ls7))\n",
    "print(np.sum(ls5_2010_test> best_cutoff_ls5))\n",
    "print(np.sum(test_masks))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reservoir-openvino",
   "language": "python",
   "name": "reservoir-openvino"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
