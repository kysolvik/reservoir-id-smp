{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_process_csv_to_gdf(csv):\n",
    "    temp_df = pd.read_csv(csv)\n",
    "    temp_df['satellite'] = os.path.basename(csv)[:8]\n",
    "    temp_df['year'] = int(os.path.basename(csv)[9:13])\n",
    "    # temp_df = temp_df.loc[temp_df['hydropoly_max']<100]\n",
    "    temp_df['area_ha'] = temp_df['area']*100/10000 # HA\n",
    "    temp_df['area_km'] = temp_df['area']*100/(1000*1000) # km2\n",
    "    # temp_df = temp_df.loc[temp_df['area_ha']<100] # Remove greater than 100 ha\n",
    "    temp_gdf = gpd.GeoDataFrame(\n",
    "        temp_df, geometry=gpd.points_from_xy(temp_df.longitude, temp_df.latitude),\n",
    "        crs='EPSG:4326'\n",
    "    )\n",
    "    return temp_gdf\n",
    "\n",
    "def read_process_region_csv(csv):\n",
    "    temp_df = pd.read_csv(csv)\n",
    "    temp_df['satellite'] = os.path.basename(csv)[:8]\n",
    "    temp_df['year'] = int(os.path.basename(csv)[9:13])\n",
    "\n",
    "    return temp_df\n",
    "\n",
    "def sjoin_summarize(points_gdf, poly_gdf, poly_field):\n",
    "    \n",
    "    joined_gdf = gpd.sjoin(points_gdf, poly_gdf, predicate='within', how='inner')\n",
    "    return joined_gdf.groupby(poly_field).count()\n",
    "\n",
    "def sjoin_summarize_nogroup(points_gdf, poly_gdf):\n",
    "    joined_gdf = gpd.sjoin(points_gdf, poly_gdf, predicate='within', how='inner')\n",
    "    return joined_gdf[['area_ha']].agg(['sum', 'count', 'median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_gdf = read_process_csv_to_gdf('../clean_summarize/out/sentinel_2021_v6_wgs84_combined_merged.csv')\n",
    "res_gdf = res_gdf.loc[res_gdf['hydropoly_max']<100]\n",
    "res_gdf['area_ha'] = res_gdf['area']*100/10000 # HA\n",
    "res_gdf['area_km'] = res_gdf['area']*100/(1000*1000) # km2\n",
    "res_gdf = res_gdf.loc[res_gdf['area_ha']<100]\n",
    "res_gdf['area_m'] = res_gdf['area']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdw_df = gpd.read_file('../../../../reservoir-id-cnn/reservoir-id-cnn/analysis/other_dams/gdw/GDW_v1_0_shp/GDW_barriers_v1_0.shp')\n",
    "gdw_df = gdw_df.loc[gdw_df['COUNTRY']=='Brazil']\n",
    "gdw_df_allhydro = gdw_df.loc[gdw_df['USE_ELEC'].isin(['Main', 'Sec'])]\n",
    "gdw_df = gdw_df.loc[gdw_df['AREA_POLY'] <1]\n",
    "gdw_df = gdw_df.loc[gdw_df['AREA_POLY'] > -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_gdf = gpd.read_file('../compare_other_methods/data/ana/Massas_d_Agua.shp')\n",
    "ana_gdf = ana_gdf.loc[ana_gdf['detipomass']=='Artificial']\n",
    "ana_gdf['geometry'] = ana_gdf['geometry'].centroid\n",
    "ana_gdf = ana_gdf.to_crs('EPSG:4326')\n",
    "ana_gdf_allhydro = ana_gdf.loc[ana_gdf['usoprinc']=='Hidrel√©trica']\n",
    "ana_gdf = ana_gdf.loc[ana_gdf['nuareakm2']<1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reservoirs per watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_name='nunivotto6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dissolved_wgs84_path = './data/watersheds_2017_{}.shp'.format(level_name)\n",
    "if not os.path.isfile(dissolved_wgs84_path):\n",
    "    state_gdf = gpd.read_file('./data/Brazilian_States.shp').to_crs('EPSG:4326')\n",
    "    watershed_gdf = gpd.read_file('data/bho_2017_v_01_05_50k.gpkg', layer='pgh_output.geoft_bho_area_drenagem'\n",
    "                                    ).to_crs('EPSG:4326'\n",
    "                                            ).dissolve(by=level_name\n",
    "                                                    ).clip(state_gdf)\n",
    "    watershed_gdf['area_km2'] = watershed_gdf.to_crs('ESRI:102033').area/(1000*1000)\n",
    "    watershed_gdf.to_file(dissolved_wgs84_path)\n",
    "    watershed_gdf = watershed_gdf.reset_index()\n",
    "else:\n",
    "    watershed_gdf = gpd.read_file(dissolved_wgs84_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_watershed = sjoin_summarize(res_gdf, watershed_gdf, level_name)\n",
    "gdw_watershed = sjoin_summarize(gdw_df, watershed_gdf, level_name)\n",
    "gdw_hydro_watershed = sjoin_summarize(gdw_df_allhydro, watershed_gdf, level_name)\n",
    "ana_watershed = sjoin_summarize(ana_gdf, watershed_gdf, level_name)\n",
    "ana_hydro_watershed = sjoin_summarize(ana_gdf_allhydro, watershed_gdf, level_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(watershed_gdf.shape)\n",
    "print(res_watershed.shape[0]/watershed_gdf['nunivotto6'].unique().shape[0])\n",
    "print(gdw_watershed.shape[0]/watershed_gdf['nunivotto6'].unique().shape[0])\n",
    "print(gdw_hydro_watershed.shape[0]/watershed_gdf['nunivotto6'].unique().shape[0])\n",
    "print(ana_watershed.shape[0]/watershed_gdf['nunivotto6'].unique().shape[0])\n",
    "print(ana_hydro_watershed.shape[0]/watershed_gdf['nunivotto6'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catchment Area Fragmentation Index (CAFI)\n",
    "\n",
    "Did not end up using this, because it heavily weights downstream barriers compared to headwaters.\n",
    "\n",
    "For example, a single dam was located at the outlet of a river would result in CAFI saying the watershed was 100% fragmented\n",
    "\n",
    "Since most of our reservoirs are in headwaters, CAFI is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_acc = rioxarray.open_rasterio(\"data/sa_acc_3s.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_indexer = {\n",
    "    'x':xr.DataArray(res_gdf['longitude'].values, dims=['res']),\n",
    "    'y':xr.DataArray(res_gdf['latitude'].values, dims=['res'])\n",
    "}\n",
    "res_upstream_area =  flow_acc.sel(xr_indexer, method='nearest')\n",
    "res_vals = res_upstream_area.values\n",
    "print(res_vals.sum())\n",
    "print(res_vals.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdw_indexer = {\n",
    "    'x':xr.DataArray(gdw_df['LONG_DAM'].values, dims=['res']),\n",
    "    'y':xr.DataArray(gdw_df['LAT_DAM'].values, dims=['res'])\n",
    "}\n",
    "gdw_upstream_area =  flow_acc.sel(gdw_indexer, method='nearest')\n",
    "gdw_vals = gdw_upstream_area.values\n",
    "print(gdw_vals.sum())\n",
    "print(gdw_vals.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ana_indexer = {\n",
    "    'x':xr.DataArray(ana_gdf.geometry.x, dims=['res']),\n",
    "    'y':xr.DataArray(ana_gdf.geometry.y, dims=['res'])\n",
    "}\n",
    "ana_upstream_area =  flow_acc.sel(ana_indexer, method='nearest')\n",
    "ana_vals = ana_upstream_area.values\n",
    "print(ana_vals.sum())\n",
    "print(ana_vals.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resgis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
