{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_gpkg = './data/pa_br_landtenure_studyarea_only.gpkg'\n",
    "area_col = 'area_ha'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_gdf = gpd.read_file(prop_gpkg)\n",
    "prop_gdf = prop_gdf.rename(columns={area_col:'prop_area'})\n",
    "prop_gdf.loc[:,'fid'] = prop_gdf.index + 1\n",
    "prop_gdf = prop_gdf.to_crs('EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_df = pd.read_csv('/home/ksolvik/research/reservoirs/interviews/summer_2023/locs/fazendas_cleaned_ids.csv')\n",
    "interview_df['int_index'] = interview_df.index + 1\n",
    "# old_ids = interview_df['int_index'].values.copy()\n",
    "# np.random.shuffle(old_ids)\n",
    "# interview_df['anon_id'] = old_ids\n",
    "# interview_df.to_csv('/home/ksolvik/research/reservoirs/interviews/summer_2023/locs/fazendas_cleaned_ids.csv', index=False)\n",
    "interview_gdf = gpd.GeoDataFrame(\n",
    "    interview_df, geometry=gpd.points_from_xy(interview_df.lon, interview_df.lat),\n",
    "    crs='EPSG:4326'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial join\n",
    "int_prop_gdf = gpd.sjoin(interview_gdf, prop_gdf, predicate='within', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reservoir info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_gdf_res = int_prop_gdf.loc[~int_prop_gdf['fid'].isna()]\n",
    "prop_gdf_res = prop_gdf_res.drop_duplicates(['fid'])\n",
    "prop_gdf_res = prop_gdf_res.set_index('fid')\n",
    "prop_gdf_res.columns = pd.MultiIndex.from_product([[0], prop_gdf_res.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reservoir info\n",
    "for y in np.arange(1984, 2024): \n",
    "    df_list = []\n",
    "    for ls_csv in glob.glob('./out/res_stats_buffer/prop_res_stats_*{}.csv'.format(y)):\n",
    "        res_df = pd.read_csv(ls_csv).set_index('fid')\n",
    "        df_list.append(res_df.fillna(0))\n",
    "    # Calc mean if multiple satellites\n",
    "    year_res_df = pd.concat(df_list, axis=1).groupby(axis=1, level=0).mean()\n",
    "    year_res_df.columns = pd.MultiIndex.from_arrays([[y]*3, year_res_df.columns])\n",
    "    prop_gdf_res = prop_gdf_res.join(year_res_df,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index to interview id\n",
    "prop_gdf_res[(0, 'fid')] = prop_gdf_res.index.astype(int)\n",
    "prop_gdf_res.index = prop_gdf_res[(0, 'int_index')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prop_res_history(id):\n",
    "    print('Property Info:')\n",
    "    temp_df = prop_gdf_res.loc[id]\n",
    "    print(temp_df[0])\n",
    "    ax =temp_df.drop(0)[:, 'sum'].plot()\n",
    "    temp_df.drop(0)[:, 'count'].plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MapBiomas Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mb_keys_dict = {\n",
    "    'crop': np.array([18,19,39,20,40,62,41,36,46,47,35,48]),\n",
    "    'forest': np.array([3]),\n",
    "    'savanna': np.array([4]),\n",
    "    'grassland':np.array([12]),\n",
    "    'pasture': np.array([15])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_lulc_classes(in_df):\n",
    "    out_df = pd.DataFrame()\n",
    "    for lulc_class in mb_keys_dict.keys():\n",
    "        sum_of_class = in_df.loc[:, np.in1d(in_df.columns.astype(int), mb_keys_dict[lulc_class])].sum(axis=1)\n",
    "        out_df[lulc_class] = sum_of_class\n",
    "    # out_df = out_df.div((out_df.sum(axis=1)), axis=0)*100\n",
    "    out_df = out_df*90000/(1000*1000)\n",
    "    out_df['natural'] = out_df[['forest','savanna','grassland']].sum(axis=1)\n",
    "    out_df.columns = pd.MultiIndex.from_product([[y],out_df.columns])\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_gdf_lulc = int_prop_gdf.loc[~int_prop_gdf['fid'].isna()]\n",
    "prop_gdf_lulc = prop_gdf_lulc.drop_duplicates(['fid'])\n",
    "prop_gdf_lulc = prop_gdf_lulc.set_index('fid')\n",
    "prop_gdf_lulc.columns = pd.MultiIndex.from_product([[0], prop_gdf_lulc.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in np.arange(1985, 2024):\n",
    "    year_csv_path = './out/mb_stats/prop_mb_stats{}.csv'.format(y)\n",
    "    year_df = pd.read_csv(year_csv_path, index_col=0)\n",
    "    year_df.index = year_df.index.astype(int)\n",
    "    lulc_df = assign_lulc_classes(year_df)\n",
    "    prop_gdf_lulc = prop_gdf_lulc.join(lulc_df)\n",
    "    prop_gdf_lulc[(y, 'other')] = prop_gdf_lulc[(0, 'prop_area')] - lulc_df.loc[:,pd.IndexSlice[y, ['crop','natural','pasture']]].sum(axis=1)\n",
    "    prop_gdf_lulc.loc[prop_gdf_lulc[(y, 'other')]<0, (y, 'other')] = 0\n",
    "\n",
    "# Set index to interview id\n",
    "prop_gdf_lulc[(0, 'fid')] = prop_gdf_lulc.index.astype(int)\n",
    "prop_gdf_lulc.index = prop_gdf_lulc[(0, 'int_index')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_prop_lulc_history(fid, combine_natural=True):\n",
    "    print('Property Info:')\n",
    "    temp_df = prop_gdf_lulc.loc[fid]\n",
    "    print(temp_df[0])\n",
    "    if combine_natural:\n",
    "        df_to_plot = temp_df.drop(0).unstack(level=1).drop(columns=['forest','savanna','grassland'])\n",
    "    else:\n",
    "        df_to_plot = temp_df.drop(0).unstack(level=1).drop(columns=['natural'])\n",
    "    df_to_plot.plot.area()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot LULC and reservoir history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_class_color_list = ['pink','sienna','darkgreen', 'slategrey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prop_twoax(fid, combine_natural=True, print_info=True, include_note=False):\n",
    "    fig, ax = plt.subplots(1,1, figsize=[7.35, 4])\n",
    "    lulc_temp_df = prop_gdf_lulc.loc[fid]\n",
    "    if print_info:\n",
    "        print('Property Info:')\n",
    "        print(lulc_temp_df[0])\n",
    "    # LULC\n",
    "    if combine_natural:\n",
    "        lulc_df_to_plot = lulc_temp_df.drop(0,level=0).unstack(level=1).drop(columns=['forest','savanna','grassland'])\n",
    "    else:\n",
    "        lulc_df_to_plot = lulc_temp_df.drop(0,level=0).unstack(level=1).drop(columns=['natural'])\n",
    "    lulc_df_to_plot.columns=[c.capitalize() for c in lulc_df_to_plot.columns]\n",
    "    lulc_df_to_plot.plot.area(ax=ax, color=ag_class_color_list, legend=False)\n",
    "    # Reservoirs\n",
    "    ax2 = ax.twinx()  # instantiate a second Axes that shares the same x-axis\n",
    "\n",
    "    prop_df_to_plot = prop_gdf_res.loc[fid].drop(0,level=0).drop(['median','count'], level=1).fillna(0)\n",
    "    prop_df_to_plot.unstack(level=1).rename(columns={'sum':'Reservoir Area'}).plot(ax=ax2, color='black', lw=1.5, style='--', legend=False)\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_xlim([1985, 2023])\n",
    "    ax.set_ylabel('Land Area (ha)')\n",
    "    ax2.set_ylabel('Total Res Surface Area (ha)')\n",
    "    if include_note:\n",
    "        ax.set_title(lulc_temp_df[(0, 'Note')] + '\\n'\n",
    "                     + lulc_temp_df[(0,'Transcript')] + ' ' + str(fid))\n",
    "\n",
    "def plot_prop_twoax_7(fids, combine_natural=True, include_note=False, include_title=True):\n",
    "    fig, axs = plt.subplots(4,2, figsize=(7.35,7.35))\n",
    "    alphabet_list = string.ascii_uppercase\n",
    "    for i, fid in enumerate(fids): \n",
    "        ax = axs.flatten()[i]\n",
    "        lulc_temp_df = prop_gdf_lulc.loc[fid]\n",
    "        # LULC\n",
    "        if combine_natural:\n",
    "            lulc_df_to_plot = lulc_temp_df.drop(0,level=0).unstack(level=1).drop(columns=['forest','savanna','grassland'])\n",
    "        else:\n",
    "            lulc_df_to_plot = lulc_temp_df.drop(0,level=0).unstack(level=1).drop(columns=['natural'])\n",
    "        lulc_df_to_plot.columns=[c.capitalize() for c in lulc_df_to_plot.columns]\n",
    "        lulc_df_to_plot.plot(kind='area',\n",
    "            ax=ax, color=ag_class_color_list, legend=False, aa=True,lw=0.01)\n",
    "        # Reservoirs\n",
    "        ax2 = ax.twinx()  # instantiate a second Axes that shares the same x-axis\n",
    "\n",
    "        prop_df_to_plot = prop_gdf_res.loc[fid].drop(0,level=0).drop(['median','count'], level=1).fillna(0)\n",
    "        prop_df_to_plot.unstack(level=1).rename(columns={'sum':'Reservoir Area'}).plot(\n",
    "            ax=ax2, color='black', lw=1.5, style='--', legend=False)\n",
    "        ax.set_xlabel('Year')\n",
    "        ax.set_xlim([1985, 2023])\n",
    "        ax.set_ylim([0, np.min(lulc_df_to_plot.sum(axis=1).values)])\n",
    "        ax.set_ylabel('Land Area (ha)')\n",
    "        ax2.set_ylabel('Res Aea (ha)')\n",
    "        max_res_area = np.max(prop_df_to_plot.unstack(level=1).values)\n",
    "        if max_res_area < 5:\n",
    "            ax2.set_ylim(-0.1, 5)\n",
    "        else:\n",
    "            ax2.set_ylim(-0.1, max_res_area+5)\n",
    "            ax.yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "        if include_note:\n",
    "            ax.set_title(lulc_temp_df[(0,'Note')] + str(fid))\n",
    "        elif include_title: \n",
    "            ax.set_title('({}) {}'.format(alphabet_list[i], lulc_temp_df[(0, 'Title')]))\n",
    "        else:\n",
    "            ax.set_title('#{}'.format(lulc_temp_df[(0,'anon_id')]))\n",
    "\n",
    "    # Add legend\n",
    "    # Last axis\n",
    "    ax=axs[-1,-1]\n",
    "    ax.set_axis_off()\n",
    "    handles, labels = axs[-1, -2].get_legend_handles_labels()\n",
    "    # Line marker and label\n",
    "    ax2_handle, ax2_label = ax2.get_legend_handles_labels()\n",
    "    handles.append(ax2_handle[0])\n",
    "    labels.append(ax2_label[0])\n",
    "\n",
    "    ax.legend(handles, labels,loc=10,\n",
    "                fontsize=12)\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot:\n",
    "props_to_plots=[5, 35, 2, 28, 1, 9, 45]\n",
    "plot_prop_twoax_7(props_to_plots, include_title=True, include_note=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot them all\n",
    "for id in prop_gdf_res.index:\n",
    "    plot_prop_twoax(id, print_info=False, include_note=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resgis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
