{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2229d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import glob\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import subprocess as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639aa67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96dc3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = './data/sentinel/'\n",
    "out_dir = './data/reservoirs_10band/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04f85b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.call(['mkdir', '-p', out_dir + 'img_dir/train'])\n",
    "sp.call(['mkdir', '-p', out_dir + 'img_dir/val'])\n",
    "sp.call(['mkdir', '-p', out_dir + 'img_dir/test'])\n",
    "\n",
    "sp.call(['mkdir', '-p', out_dir + 'ann_dir/train'])\n",
    "sp.call(['mkdir', '-p', out_dir + 'ann_dir/val'])\n",
    "sp.call(['mkdir', '-p', out_dir + 'ann_dir/test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d6cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_frac = 0.2\n",
    "test_frac = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecb6a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cloudy_images = True\n",
    "cloudy_csv = './data/cloud_images.csv'\n",
    "replace_bad_masks = True\n",
    "bad_mask_csv = './data/replace_w_zeromask.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4780d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if remove_cloudy_images:\n",
    "    cloudy_base_list = pd.read_csv(cloudy_csv)['name'].values\n",
    "else:\n",
    "    cloudy_base_list = np.array([])\n",
    "if replace_bad_masks:\n",
    "    replace_mask_base_list = pd.read_csv(bad_mask_csv)['name'].values\n",
    "else:\n",
    "    replace_mask_base_list = np.array([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3851fa1c",
   "metadata": {},
   "source": [
    "## First round of loading data:\n",
    " 1. Save mins and maxes of every band for every image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3253d39",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Get mask image names and base image patterns\n",
    "mask_images = glob.glob('{}*mask.png'.format(input_dir))\n",
    "mask_images.sort()\n",
    "image_patterns = [mi.replace('mask.png', '') for mi in mask_images]\n",
    "image_patterns = np.array([image_pat for image_pat in image_patterns if not os.path.basename(image_pat) in cloudy_base_list])\n",
    "    \n",
    "\n",
    "band_mins = []\n",
    "band_maxes = []\n",
    "                  \n",
    "for image_base in image_patterns:\n",
    "    stacked_ar = np.concatenate([\n",
    "        io.imread('{}og.tif'.format(image_base)),\n",
    "        io.imread('{}s1_v2_og.tif'.format(image_base)),\n",
    "        io.imread('{}s2_20m_og.tif'.format(image_base)),\n",
    "\n",
    "    ], axis=2)\n",
    "    \n",
    "    img_min = np.min(stacked_ar, axis=(0,1))\n",
    "    img_max = np.max(stacked_ar, axis=(0,1))\n",
    "    \n",
    "    \n",
    "    band_mins += [img_min]\n",
    "    band_maxes += [img_max]\n",
    "\n",
    "all_mins = np.stack(band_mins)\n",
    "all_maxes = np.stack(band_maxes)\n",
    "bands_min_max_all_imgs = np.stack([all_mins, all_maxes], axis=0)\n",
    "np.save('./data/all_imgs_bands_min_max_sentinel_v7.npy', bands_min_max_all_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b343a82",
   "metadata": {},
   "source": [
    "## Second round of loading data:\n",
    "1. Skip any cloudy images\n",
    "2. Split into train, val, test\n",
    "3. Rescale bands using the previously calculated min and max\n",
    "4. Calc NDs\n",
    "5. Select 3 bands for feeding into CNN\n",
    "6. Calc mean and std in running fashion for those bands, print it out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63daa78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_min_max_all_imgs = np.load('./data/bands_minmax/all_imgs_bands_min_max_sentinel_v7.npy')\n",
    "bands_min_max = np.array([np.min(bands_min_max_all_imgs[0], axis=0),\n",
    "                          np.percentile(bands_min_max_all_imgs[1], 80, axis=0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccab4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_diff(ar1, ar2):\n",
    "    \"\"\"Returns normalized difference of two arrays.\"\"\"\n",
    "    \n",
    "    return np.nan_to_num(((ar1 - ar2) / (ar1 + ar2)),0)\n",
    "    \n",
    "    \n",
    "def calc_nd(img, band1, band2):\n",
    "    \"\"\"Add band containing NDWI.\"\"\"\n",
    "\n",
    "    nd = normalized_diff(img[:,:,band1].astype('float64'), \n",
    "                         img[:,:,band2].astype('float64'))\n",
    "    \n",
    "    # Rescale to uint8\n",
    "    nd = np.round(255.*(nd - (-1))/(1 - (-1)))\n",
    "    if nd.max()>255:\n",
    "        print(nd.max())\n",
    "        print('Error: overflow')\n",
    "   \n",
    "    return nd.astype(np.uint8)\n",
    "\n",
    "def calc_all_nds(img):\n",
    "    nd_list =[]\n",
    "    \n",
    "    # Add  Gao NDWI\n",
    "    nd_list += [calc_nd(img, 3, 11)]\n",
    "    # Add  MNDWI\n",
    "    nd_list += [calc_nd(img, 1, 11)]\n",
    "    # Add McFeeters NDWI band\n",
    "    nd_list += [calc_nd(img, 1, 3)]\n",
    "    # Add NDVI band\n",
    "    nd_list += [calc_nd(img, 3, 2)]\n",
    "\n",
    "    return np.stack(nd_list, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fda0641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_to_minmax_uint8(img, bands_min_max):\n",
    "    img = np.where(img > bands_min_max[1], bands_min_max[1], img)\n",
    "    img  = (255. * (img.astype('float64') - bands_min_max[0]) / (bands_min_max[1] - bands_min_max[0]))\n",
    "    img = np.round(img)\n",
    "    if img.max()>255:\n",
    "        print(img.max())\n",
    "        print('Error: overflow')\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "def select_bands_save_png(fp_base, out_path, band_selection, bands_min_max, crop_size, resample_size,\n",
    "                          calc_mean_std=False):\n",
    "    ar = np.concatenate([\n",
    "        io.imread('{}og.tif'.format(fp_base)),\n",
    "        io.imread('{}s1_v2_og.tif'.format(fp_base)),\n",
    "        io.imread('{}s2_20m_og.tif'.format(fp_base))\n",
    "    ], axis=2)\n",
    "\n",
    "    ar = rescale_to_minmax_uint8(ar, bands_min_max)\n",
    "    \n",
    "    nds = calc_all_nds(ar)\n",
    "    \n",
    "    ar = np.concatenate([ar, nds], axis=2)[:, :, band_selection]\n",
    "    \n",
    "    if ar.shape[:-1] != crop_size:\n",
    "        ar = crop(ar, crop_size)\n",
    "    if ar.shape[:-1] != resample_size:\n",
    "        ar = resize(ar, resample_size, preserve_range=True).astype(np.uint8)\n",
    "    io.imsave(out_path, ar)\n",
    "    if calc_mean_std:\n",
    "        return ar.reshape((-1, len(band_selection)))\n",
    "    \n",
    "def crop(img, out_size):\n",
    "    crop_size = int((img.shape[0] - out_size[0])/2)\n",
    "    img = img\n",
    "    return img[crop_size:(-crop_size), crop_size:(-crop_size)]\n",
    "\n",
    "def create_nband_pngs(img_list, output_dir, band_selection = [0, 1, 2, 3, 4, 5, 12, 13, 14, 15], crop_size=(640,640),\n",
    "                      resample_size=(640, 640),\n",
    "                      calc_mean_std=False):\n",
    "    if calc_mean_std:\n",
    "        n = 0\n",
    "        mean = np.zeros(len(band_selection))\n",
    "        sums =  np.zeros(len(band_selection))\n",
    "        M2 =  np.zeros(len(band_selection))\n",
    "\n",
    "    for fp_base in img_list:\n",
    "        # out_path is a little tricky, need to remove _ at end and add in .png\n",
    "        out_path = fp_base.replace(input_dir, output_dir)[:-1] + '.tif'\n",
    "        if calc_mean_std:\n",
    "            vals = select_bands_save_png(fp_base, out_path, band_selection, \n",
    "                                         bands_min_max, crop_size, resample_size, \n",
    "                                         calc_mean_std=calc_mean_std)\n",
    "            n += vals.shape[0]\n",
    "            vals = vals\n",
    "            sums += np.sum(vals, axis=0)\n",
    "            delta = vals - mean\n",
    "            mean += np.sum(delta/n, axis=0)\n",
    "            M2 += np.sum(delta*(vals - mean), axis=0)\n",
    "        else:\n",
    "            select_bands_save_png(fp_base, out_path, band_selection, bands_min_max, crop_size, resample_size)\n",
    "            \n",
    "    if calc_mean_std:\n",
    "        return sums/n, np.sqrt(M2 / (n - 1))\n",
    "    \n",
    "        \n",
    "def save_mask_pngs(ann_list, output_dir, resample_size=(500, 500)):\n",
    "    total_res_pixels = 0\n",
    "    for fp_base in ann_list:\n",
    "        fp = '{}mask.png'.format(fp_base)\n",
    "        ar = io.imread(fp)\n",
    "        ar[ar>0] = 1\n",
    "        \n",
    "        # Sometimes the pngs have 3 dims. We only want 2\n",
    "        if len(ar.shape) > 2:\n",
    "            ar = ar[:,:,0]\n",
    "            \n",
    "        # Replace bad masks\n",
    "        if os.path.basename(fp).replace('_mask.png', '') in replace_mask_base_list:\n",
    "            ar[:] = 0\n",
    "        \n",
    "        # Replace if only 1 positive pixel\n",
    "        ar_sum = ar.sum()\n",
    "        if ar_sum == 1:\n",
    "            ar[:] = 0\n",
    "        else:\n",
    "            total_res_pixels += ar_sum\n",
    "            \n",
    "        # Resize\n",
    "        if ar.shape != resample_size:\n",
    "            ar = np.round(resize(ar, resample_size, preserve_range=True)).astype(np.uint8)\n",
    "\n",
    "        if np.sum(np.logical_and(ar!=1, ar!=0)) > 0:\n",
    "            print(fp)\n",
    "            print(np.unique(ar))\n",
    "            raise ValueError('Mask has non-0 and/or non-1 values')\n",
    "            \n",
    "        # Save\n",
    "        out_path = fp.replace(input_dir, output_dir).replace('_mask.png', '.png')\n",
    "        io.imsave(out_path, ar)\n",
    "        \n",
    "    return total_res_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8683dc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(img_patterns, test_frac, val_frac):\n",
    "    \"\"\"Split data into train, test, val (or just train)\n",
    "\n",
    "    Returns:\n",
    "        train_indices, val_indices, test_indices tuple\n",
    "    \"\"\"\n",
    "    total_ims = len(img_patterns)\n",
    "    if test_frac != 0:\n",
    "\n",
    "        train_count = round(total_ims * (1 - test_frac - val_frac))\n",
    "        train_indices = random.sample(range(total_ims), train_count)\n",
    "        test_val_indices = np.delete(np.array(range(total_ims)), train_indices)\n",
    "\n",
    "        test_count = round(total_ims * test_frac)\n",
    "        test_indices = random.sample(list(test_val_indices), test_count)\n",
    "\n",
    "\n",
    "        if val_frac != 0:\n",
    "            val_indices = np.delete(np.array(range(total_ims)),\n",
    "                                    np.append(train_indices, test_indices))\n",
    "\n",
    "            return train_indices, val_indices, test_indices\n",
    "        else: \n",
    "            return train_indices, test_indices\n",
    "    else:\n",
    "        return np.arange(total_ims)\n",
    "\n",
    "# Get train, test, and val lists, skipping cloudy images\n",
    "def list_and_split_imgs(input_dir, cloudy_base_list):\n",
    "    # First get list of images\n",
    "    mask_images = glob.glob('{}*mask.png'.format(input_dir))\n",
    "    mask_images.sort()\n",
    "    image_patterns = [mi.replace('mask.png', '') for mi in mask_images]\n",
    "    image_patterns = np.array([image_pat for image_pat in image_patterns if not os.path.basename(image_pat) in cloudy_base_list])\n",
    "    \n",
    "    # No floodplain images in test set\n",
    "    floodplain_images = np.array([ip for ip in image_patterns if 'floodplains' in ip])\n",
    "    non_floodplain_images = np.array([ip for ip in image_patterns if 'floodplains' not in ip])\n",
    "    train_indices, val_indices, test_indices = split_train_test(non_floodplain_images, test_frac=test_frac, val_frac=val_frac)\n",
    "    # For including FP in val Using test_frac arg because allows for no 3rd split\n",
    "    # train_indices_fp, val_indices_fp = split_train_test(floodplain_images, test_frac=val_frac, val_frac=0)\n",
    "#     train_basename_list = np.concatenate([non_floodplain_images[train_indices], floodplain_images[train_indices_fp]])\n",
    "#     val_basename_list = np.concatenate([non_floodplain_images[val_indices], floodplain_images[val_indices_fp]])\n",
    "#     test_basename_list = non_floodplain_images[test_indices]\n",
    "    # For only putting fp in train\n",
    "    train_basename_list = np.concatenate([non_floodplain_images[train_indices], floodplain_images])\n",
    "    val_basename_list = non_floodplain_images[val_indices]\n",
    "    test_basename_list = non_floodplain_images[test_indices]\n",
    "    \n",
    "    return train_basename_list, val_basename_list, test_basename_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07bf7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_basename_list, val_basename_list, test_basename_list = list_and_split_imgs(input_dir, cloudy_base_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a1b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_std = create_nband_pngs(train_basename_list, output_dir = '{}/img_dir/train/'.format(out_dir),\n",
    "                              calc_mean_std = True)\n",
    "create_nband_pngs(test_basename_list, output_dir = '{}/img_dir/test/'.format(out_dir), calc_mean_std = False)\n",
    "create_nband_pngs(val_basename_list, output_dir = '{}/img_dir/val/'.format(out_dir), calc_mean_std = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feb3c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_res_pixels = save_mask_pngs(train_basename_list, output_dir = '{}/ann_dir/train/'.format(out_dir))\n",
    "save_mask_pngs(test_basename_list, output_dir = '{}/ann_dir/test/'.format(out_dir))\n",
    "save_mask_pngs(val_basename_list, output_dir = '{}/ann_dir/val/'.format(out_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5237037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./mean_std_sentinel_v7.npy', np.vstack(means_std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reservoir-gaip",
   "language": "python",
   "name": "reservoir-gaip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
